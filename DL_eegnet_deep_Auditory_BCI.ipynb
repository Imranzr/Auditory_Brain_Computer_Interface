{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOK4k6TeRgLmqbeFx14CJpr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"0Pbv_JntYilF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install mne"],"metadata":{"id":"PkJU4ZqMYkIW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install pyriemann"],"metadata":{"id":"oCZDBjQpYl_e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import argparse\n","import sys\n","import mne\n","import math\n","import time\n","import json\n","import numpy as np\n","from scipy.signal import butter, filtfilt\n","from pyriemann.estimation import XdawnCovariances\n","from pyriemann.tangentspace import TangentSpace\n","from sklearn.pipeline import make_pipeline\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, matthews_corrcoef\n","\n","start = time.time()\n","\n","\n","def is_notebook():\n","    try:\n","        shell = get_ipython().__class__.__name__\n","        if shell == 'ZMQInteractiveShell':\n","            return True\n","        elif shell == 'TerminalInteractiveShell':\n","            return False\n","        else:\n","            return False\n","    except NameError:\n","        return False\n","if is_notebook():\n","    args = argparse.Namespace(s=None, c=None)\n","else:\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('-s', default=None)\n","    parser.add_argument('-c', default=None, type=int)\n","    args = parser.parse_args(args=[])\n","\n","print(args.s)\n","print(args.c)\n","\n","print(__doc__)\n","\n","subject = 'sub-I'\n","if args.s is not None:\n","    subject = args.s\n","test_class =1\n","if args.c is not None:\n","    test_class = args.c\n","\n","import numpy as np\n","fnum = np.array([[1,4],\n","                 [2,5],\n","                 [3,6]])\n","\n","trig_id = [2,8,32]\n","tasks = ['low', 'low', 'mid', 'mid', 'high', 'high']\n","reject={'eeg':100e-6,'eog':500e-6}\n","\n","import os\n","import json\n","repository_base = os.path.dirname(os.path.dirname(os.path.abspath('/content/drive/MyDrive/dataverse_files/results/sub-I_classification_scores.json')))\n","\n","base = os.path.join(repository_base, \"eeg\")\n","save_base = os.path.join(repository_base, \"results\")\n","if not os.path.exists(save_base):\n","    os.makedirs(save_base)\n","\n","Fs = 1000\n","fc = [1, 40]\n","resample = None\n","from scipy.signal import butter, filtfilt\n","def apply_filter(data, b, a):\n","    r = filtfilt(b=b, a=a, x=data)\n","    return r\n","b,a = butter(N = 2, Wn = np.array(fc)/(Fs/2), btype = 'bandpass', output = 'ba')\n","\n","\n","\n","t_file = []\n","nt_file = []\n","target_file = []\n","non_target_file = []\n","\n","\n","for i in range(len(fnum.ravel())):\n","    fname = os.path.join(base, subject, \"eeg\", \"%s_task-%s_run-%d_eeg.vhdr\" % (subject, tasks[i], fnum.ravel()[i]))\n","    print(fname)\n","    if np.any(fnum[test_class-1] == fnum.ravel()[i]):\n","        if isinstance(target_file, list):\n","            target_file = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n","            target_file = target_file.apply_function(apply_filter, channel_wise=True, b=b, a=a)\n","            t_file.append(fnum.ravel()[i])\n","        else:\n","            tmp = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n","            tmp = tmp.apply_function(apply_filter, channel_wise=True, b=b, a=a)\n","            target_file = mne.concatenate_raws([target_file, tmp])\n","            t_file.append(fnum.ravel()[i])\n","    else:\n","        if isinstance(non_target_file, list):\n","            non_target_file = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n","            non_target_file = non_target_file.apply_function(apply_filter, channel_wise=True, b=b, a=a)\n","            nt_file.append(fnum.ravel()[i])\n","        else:\n","            tmp = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n","            tmp = tmp.apply_function(apply_filter, channel_wise=True, b=b, a=a)\n","            non_target_file = mne.concatenate_raws([non_target_file, tmp])\n","            nt_file.append(fnum.ravel()[i])\n","if resample is not None:\n","    target_file.resample(resample)\n","    non_target_file.resample(resample)\n","if resample != None:\n","    target_file.resample(resample)\n","    non_target_file.resample(resample)\n","\n","\n","event_id={'target_stimulus_id':-100,'non_target_stimulus_id':-500}\n","target_eve = mne.events_from_annotations(target_file)\n","target_eve = mne.merge_events(target_eve[0],[trig_id[test_class-1]],event_id['target_stimulus_id'],replace_events=True)\n","non_target_eve = mne.events_from_annotations(non_target_file)\n","non_target_eve = mne.merge_events(non_target_eve[0],[trig_id[test_class-1]],event_id['non_target_stimulus_id'],replace_events=True)\n","\n","\n","\n","tmin,tmax= -0.02, 1.4\n","baseline=(0.0,0.01)\n","target_epochs = mne.Epochs(target_file,events=target_eve, event_id=event_id['target_stimulus_id'], tmin=tmin,tmax=tmax, baseline=baseline, reject=reject,preload = True)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","import numpy as np\n","def find_max_peak_window(data, Fs, window_size_ms=600, overlap_size_ms=200, epoch_index=0):\n","    \"\"\"\n","    Function to find the window with the maximum peak value within a specific epoch and return its start and end indices.\n","    \"\"\"\n","    window_size_samples = int(window_size_ms * Fs / 1000)\n","    overlap_size_samples = int(overlap_size_ms * Fs / 1000)\n","\n","    epoch_data = data[epoch_index]\n","    n_channels, n_times = epoch_data.shape\n","    max_peak_value = -np.inf\n","    max_peak_start_index = None\n","    max_peak_end_index = None\n","\n","\n","    start = 0\n","    while start + window_size_samples <= n_times:\n","        window_data = epoch_data[:, start:start + window_size_samples]\n","        current_peak_value = np.max(window_data)\n","        if current_peak_value > max_peak_value:\n","            max_peak_value = current_peak_value\n","            max_peak_start_index = start\n","            max_peak_end_index = start + window_size_samples - 1\n","        start += (window_size_samples - overlap_size_samples)\n","    print(f\"Epoch {epoch_index + 1} - Max Peak Value: {max_peak_value}\")\n","    print(f\"Epoch {epoch_index + 1} - Window Start Index: {max_peak_start_index}, End Index: {max_peak_end_index}\")\n","    return max_peak_start_index, max_peak_end_index\n","\n","\n","def analyze_all_epochs_max_peaks(data, Fs, window_size_ms=600, overlap_size_ms=200):\n","    \"\"\"\n","    Function to find and print the maximum peak values and corresponding window indices across all epochs.\n","    \"\"\"\n","    n_epochs = data.shape[0]\n","    peak_window_indices = []\n","    for epoch_index in range(n_epochs):\n","        print(f\"\\nAnalyzing Epoch {epoch_index + 1}\")\n","        start_index, end_index = find_max_peak_window(data, Fs, window_size_ms, overlap_size_ms, epoch_index)\n","        peak_window_indices.append((start_index, end_index))\n","    return peak_window_indices\n","\n","def re_epoch_data(data, peak_window_indices):\n","    \"\"\"\n","    Function to re-epoch the data based on the peak window indices.\n","    \"\"\"\n","    re_epoched_data = []\n","    for epoch_index, (start, end) in enumerate(peak_window_indices):\n","        re_epoched_epoch_data = data[epoch_index][:, start:end + 1]\n","        re_epoched_data.append(re_epoched_epoch_data)\n","    re_epoched_data = np.array(re_epoched_data)\n","    print(\"\\nRe-epoching complete.\")\n","    print(\"Re-epoched data shape:\", re_epoched_data.shape)\n","    return re_epoched_data\n","\n","Fs = 1000\n","data = target_epochs.get_data()\n","\n","peak_window_indices = analyze_all_epochs_max_peaks(data, Fs, window_size_ms=600, overlap_size_ms=200)\n","re_epoched_data = re_epoch_data(data, peak_window_indices)\n","\n","\n","from mne import EpochsArray\n","from mne import create_info\n","n_channels = re_epoched_data.shape[1]\n","info = create_info(ch_names=[f'chan{i}' for i in range(n_channels)], sfreq=Fs, ch_types='eeg')\n","re_epoched_epochs = EpochsArray(re_epoched_data, info)\n","\n","print(\"Re-epoched data converted to MNE Epochs:\", re_epoched_epochs)\n","from mne import EpochsArray, create_info\n","\n","\n","n_channels = re_epoched_data.shape[1]\n","info = create_info(ch_names=[f'chan{i}' for i in range(n_channels)], sfreq=Fs, ch_types='eeg')\n","re_epoched_epochs = EpochsArray(re_epoched_data, info)\n","baseline=(0.0,0.01)\n","re_epoched_epochs.apply_baseline(baseline)\n","\n","\n","re_epoched_epochs.filter(l_freq=0.50, h_freq=100.00)\n","print(\"Re-epoched data converted to MNE Epochs and processed with baseline correction and filtering.\")\n","\n","\n","\n","\n","tmin,tmax= -0.0, 0.599\n","baseline=(0.0,0.01)\n","non_target_epochs = mne.Epochs(non_target_file, events=non_target_eve, event_id=event_id['non_target_stimulus_id'], tmin=tmin,tmax=tmax, baseline=baseline, reject=reject,preload = True)\n","\n","\n","import mne\n","tmin, tmax = -0.0, 0.599\n","baseline=(0.0,0.01)\n","\n","non_target_epochs = mne.Epochs(\n","    non_target_file,\n","    events=non_target_eve,\n","    event_id=event_id['non_target_stimulus_id'],\n","    tmin=tmin,\n","    tmax=tmax,\n","    baseline=baseline,\n","    reject=reject,\n","    preload=True\n",")\n","\n","new_channel_names = [f'chan{i}' for i in range(len(non_target_epochs.ch_names))]\n","rename_dict = dict(zip(non_target_epochs.ch_names, new_channel_names))\n","non_target_epochs.rename_channels(rename_dict)\n","print(\"Updated channel names:\", non_target_epochs.ch_names)\n","\n","epochs = mne.concatenate_epochs([re_epoched_epochs, non_target_epochs])\n","epochs = epochs.copy().pick_types(eeg=True, eog=False)\n","\n","epochs_data = epochs.get_data()\n","labels = epochs.events[:, -1]\n","preds = np.zeros(len(labels))"],"metadata":{"id":"EZciigKgYoXq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["re_epoched_epochs"],"metadata":{"id":"zHwOf9jbYrva"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["non_target_epochs"],"metadata":{"id":"kQYmLmypYtyx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels"],"metadata":{"id":"Wj7VWJwTYvaR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import scipy.io as sio\n","target_data = re_epoched_epochs.get_data()\n","target_info = {\n","    'data': target_data,\n","    'times': target_epochs.times,\n","    'events': target_epochs.events,\n","    'event_id': target_epochs.event_id\n","}\n","sio.savemat('re_epoched_epochs.mat', target_info)\n","\n","\n","non_target_data = non_target_epochs.get_data()\n","non_target_info = {\n","    'data': non_target_data,\n","    'times': non_target_epochs.times,\n","    'events': non_target_epochs.events,\n","    'event_id': non_target_epochs.event_id\n","}\n","sio.savemat('non_target_epochs.mat', non_target_info)\n","\n","print(\"MAT files have been successfully saved.\")\n"],"metadata":{"id":"PW2ZurMTY4mH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["non_target_data"],"metadata":{"id":"-BmsdjD5Y6DY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"STna7kIXh8kf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch import nn"],"metadata":{"id":"xRTnffkhiBfl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import scipy.io as sio\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, cohen_kappa_score\n"],"metadata":{"id":"yOGlXVd3jMI9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","import matplotlib.pyplot as plt\n","import numpy as np"],"metadata":{"id":"OZbZbpcokQAk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = sio.loadmat(\"/content/non_target_epochs.mat\")\n"],"metadata":{"id":"ipHnr54cx3Uc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = sio.loadmat(\"/content/re_epoched_epochs.mat\")\n"],"metadata":{"id":"qXnEQYLTyFsa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y"],"metadata":{"id":"VSr8ntoOZAJ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import scipy.io as sio\n","\n","x = sio.loadmat(\"/content/non_target_epochs.mat\")\n","y = sio.loadmat(\"/content/re_epoched_epochs.mat\")\n","\n","print(\"Keys in non_target_epochs.mat:\", x.keys())\n","print(\"Keys in target_epochs.mat:\", y.keys())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qLtMWuX5ySfy","executionInfo":{"status":"ok","timestamp":1733773138484,"user_tz":-330,"elapsed":10,"user":{"displayName":"Imran Ahmad","userId":"17190214500553653263"}},"outputId":"64357ade-789d-48cf-a8f8-65619b7e02e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Keys in non_target_epochs.mat: dict_keys(['__header__', '__version__', '__globals__', 'data', 'times', 'events', 'event_id'])\n","Keys in target_epochs.mat: dict_keys(['__header__', '__version__', '__globals__', 'data', 'times', 'events', 'event_id'])\n"]}]},{"cell_type":"code","source":["print(\"non_target_epochs.mat 'data' shape:\", x['data'].shape)\n","print(\"/content/re_epoched_epochs.mat 'data' shape:\", y['data'].shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d-iiSybT1zz6","executionInfo":{"status":"ok","timestamp":1733773360059,"user_tz":-330,"elapsed":515,"user":{"displayName":"Imran Ahmad","userId":"17190214500553653263"}},"outputId":"f0d41028-235b-483e-f686-b5b87a2c472e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["non_target_epochs.mat 'data' shape: (230, 66, 600)\n","/content/re_epoched_epochs.mat 'data' shape: (100, 66, 600)\n"]}]},{"cell_type":"code","source":["class1 = x['data']\n","class2 = y['data']"],"metadata":{"id":"T6K5eXfP14_J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#x = sio.loadmat(\"/content/non_target_epochs.mat\")\n","#y = sio.loadmat(\"/content/target_epochs.mat\")\n","\n","#class1=x['Class1_filt']\n","#class2=y['Class2_filt']\n","\n","print(class1, class2)\n","result_combined = np.vstack((class1,class2))\n","\n","print(result_combined.shape)\n","\n","\n","a = class1.shape[0]\n","b = class2.shape[0]\n","\n","values = [0] * a + [1] * b\n","labels = np.array(values)\n","print(labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JgRNI3I8sVLe","executionInfo":{"status":"ok","timestamp":1733773364715,"user_tz":-330,"elapsed":464,"user":{"displayName":"Imran Ahmad","userId":"17190214500553653263"}},"outputId":"ec473743-3ae0-46a9-ebbd-789715aebedb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[[ 3.86138195e-10  2.68614242e-07  4.64585459e-07 ...  4.50300840e-06\n","    3.80228397e-06  3.11647335e-06]\n","  [ 5.68404398e-07  6.02140079e-07  5.83217467e-07 ...  2.71352334e-06\n","    2.41850751e-06  2.15767106e-06]\n","  [-4.02709215e-07 -2.46409126e-08  2.82065306e-07 ...  5.32117130e-06\n","    4.35680807e-06  3.43392922e-06]\n","  ...\n","  [ 7.39475046e-07  8.73087256e-07  9.16355099e-07 ...  8.76580464e-06\n","    8.30346373e-06  7.83795069e-06]\n","  [-2.63636364e-07 -2.63636364e-07 -1.63636364e-07 ...  4.39363636e-05\n","    4.39363636e-05  4.40363636e-05]\n","  [-1.80000000e-06 -1.00000000e-06 -5.00000000e-07 ... -1.64000000e-05\n","   -1.65000000e-05 -1.63000000e-05]]\n","\n"," [[ 2.62227660e-06  2.01844005e-06  1.37867576e-06 ...  5.18736730e-06\n","    5.26327785e-06  5.37671685e-06]\n","  [ 2.91179758e-06  2.37208863e-06  1.76771205e-06 ... -3.44766962e-06\n","   -3.36256915e-06 -3.21761136e-06]\n","  [ 1.90930893e-06  1.39249117e-06  8.68547155e-07 ...  7.49515504e-06\n","    7.42774092e-06  7.40018480e-06]\n","  ...\n","  [ 1.58698379e-06  1.25504754e-06  9.20329990e-07 ...  5.82218836e-06\n","    6.22292540e-06  6.63895693e-06]\n","  [ 6.63636364e-07  4.63636364e-07  2.63636364e-07 ...  1.96363636e-06\n","    2.36363636e-06  2.86363636e-06]\n","  [-1.60909091e-06 -1.00909091e-06 -4.09090909e-07 ... -2.28090909e-05\n","   -2.25090909e-05 -2.21090909e-05]]\n","\n"," [[ 6.45616009e-07  5.41605973e-07  4.44535746e-07 ...  1.92904414e-06\n","    1.25935583e-06  7.11628121e-07]\n","  [ 1.63665698e-06  1.08356202e-06  5.98680605e-07 ...  3.38304571e-06\n","    3.25991650e-06  3.22864910e-06]\n","  [ 2.18159113e-07  2.72470273e-07  3.19205784e-07 ... -3.42086238e-06\n","   -4.36475857e-06 -5.15586530e-06]\n","  ...\n","  [-2.81024694e-08  9.56270597e-08  1.80106254e-07 ...  5.07111597e-06\n","    4.75592230e-06  4.41370836e-06]\n","  [-3.09090909e-07 -3.09090909e-07 -2.09090909e-07 ...  3.19090909e-06\n","    2.99090909e-06  2.79090909e-06]\n","  [-7.72727273e-07 -2.72727273e-07  2.27272727e-07 ...  4.25272727e-05\n","    4.33272727e-05  4.42272727e-05]]\n","\n"," ...\n","\n"," [[ 7.74929796e-07  3.71623324e-07  3.67060993e-08 ... -4.18380624e-06\n","   -4.35008147e-06 -4.55569125e-06]\n","  [-7.68433896e-06 -8.59596305e-06 -8.51040452e-06 ... -1.99759735e-06\n","   -3.82604822e-06 -4.98632917e-06]\n","  [-1.68793074e-07 -7.80069082e-07 -1.29988031e-06 ... -1.03651894e-05\n","   -1.09234517e-05 -1.13257869e-05]\n","  ...\n","  [-5.39680130e-07 -3.61463792e-07 -2.16684670e-07 ... -1.03398985e-05\n","   -1.07031940e-05 -1.10515525e-05]\n","  [ 2.56363636e-06  2.26363636e-06  1.56363636e-06 ...  1.60636364e-05\n","    1.66636364e-05  1.72636364e-05]\n","  [-1.84545455e-06 -1.04545455e-06 -3.45454545e-07 ...  2.03545455e-05\n","    2.14545455e-05  2.23545455e-05]]\n","\n"," [[-4.44115701e-06 -4.20499263e-06 -3.66129803e-06 ... -3.54738816e-06\n","   -2.37264516e-06 -1.12773157e-06]\n","  [-9.03750496e-09 -6.28749686e-07 -1.07827146e-06 ... -1.43633147e-07\n","   -1.56339221e-07 -1.17202338e-08]\n","  [-4.06787748e-06 -3.55370120e-06 -2.87498799e-06 ... -2.34496171e-06\n","   -1.67108450e-06 -1.00346969e-06]\n","  ...\n","  [ 7.38025128e-07  6.77327803e-07  5.90224246e-07 ... -1.14645209e-05\n","   -1.07475270e-05 -1.00068039e-05]\n","  [ 5.81818182e-07  7.81818182e-07  9.81818182e-07 ... -1.01818182e-06\n","   -2.21818182e-06 -3.61818182e-06]\n","  [-2.36363636e-07  1.63636364e-07  3.63636364e-07 ...  7.76363636e-06\n","    7.96363636e-06  8.36363636e-06]]\n","\n"," [[-2.02155260e-06 -1.64605760e-06 -1.29104463e-06 ...  7.12246410e-07\n","    8.35673191e-07  1.07144248e-06]\n","  [-6.04656174e-06 -5.91437407e-06 -5.45529256e-06 ... -2.88803004e-06\n","   -1.62569409e-06 -4.11522408e-07]\n","  [ 4.31707036e-08  1.48571578e-08 -6.52178476e-09 ... -7.24883695e-06\n","   -7.71466883e-06 -7.90730054e-06]\n","  ...\n","  [-2.24212297e-06 -1.95092330e-06 -1.61190356e-06 ... -2.67700394e-06\n","   -2.71322013e-06 -2.66500963e-06]\n","  [-1.10000000e-06 -1.00000000e-06 -1.00000000e-06 ...  1.00000000e-05\n","    1.01000000e-05  1.02000000e-05]\n","  [-6.09090909e-07 -1.10909091e-06 -1.30909091e-06 ... -1.21090909e-05\n","   -1.25090909e-05 -1.30090909e-05]]] [[[ 2.57425488e-06  2.62294444e-06  2.62855119e-06 ... -7.64774286e-07\n","   -1.31916085e-06 -1.75608243e-06]\n","  [ 2.16953473e-06  2.14804786e-06  2.06182655e-06 ... -2.58277230e-07\n","   -9.29505981e-07 -1.45467749e-06]\n","  [ 3.48070292e-06  3.56401789e-06  3.57924315e-06 ... -4.11479460e-07\n","   -1.03902537e-06 -1.53523896e-06]\n","  ...\n","  [-5.93370392e-07 -7.19614289e-07 -8.57011222e-07 ... -2.08939615e-06\n","   -2.09623859e-06 -2.10268813e-06]\n","  [-3.30003695e-06 -3.29657040e-06 -3.30096886e-06 ...  3.65534163e-06\n","    3.44469881e-06  3.26370043e-06]\n","  [-1.10031889e-05 -1.19015372e-05 -1.28785126e-05 ...  3.19657948e-06\n","    2.87285724e-06  2.54426429e-06]]\n","\n"," [[ 1.50248571e-07  5.60329272e-08 -3.27707624e-08 ... -7.62313232e-07\n","   -4.64144051e-07 -2.17849937e-07]\n","  [-5.94209914e-07 -6.58718110e-07 -6.97799261e-07 ...  2.29072300e-06\n","    2.40087096e-06  2.47747858e-06]\n","  [ 7.90757184e-07  6.23389805e-07  3.76267516e-07 ... -1.48033724e-06\n","   -1.20769084e-06 -9.61158974e-07]\n","  ...\n","  [-3.50542136e-06 -3.90501677e-06 -4.38504562e-06 ...  5.58728036e-07\n","    1.22562755e-06  1.74229471e-06]\n","  [ 2.45944864e-06  2.26027023e-06  2.03817410e-06 ... -7.12559040e-07\n","   -6.81849519e-07 -6.72494978e-07]\n","  [ 4.90989634e-06  5.15700259e-06  5.74913359e-06 ... -2.15148981e-05\n","   -2.15700882e-05 -2.17198340e-05]]\n","\n"," [[-7.30593226e-07 -6.26023723e-07 -4.77545486e-07 ...  3.33289401e-06\n","    3.44093874e-06  3.50354061e-06]\n","  [-1.71795505e-06 -1.59092975e-06 -1.44485140e-06 ...  5.11199030e-06\n","    5.28398917e-06  5.33252088e-06]\n","  [-1.50700636e-06 -1.23653299e-06 -8.96970265e-07 ...  4.34289668e-06\n","    4.89995397e-06  5.29204492e-06]\n","  ...\n","  [ 3.39718707e-06  3.66978906e-06  3.93862705e-06 ...  3.56884875e-07\n","   -5.91563426e-07 -1.30138067e-06]\n","  [ 2.55348441e-06  1.90131040e-06  1.11598002e-06 ... -5.00814043e-06\n","   -4.69591037e-06 -4.42883456e-06]\n","  [-3.52977533e-07  1.66239058e-07  7.42917482e-07 ... -5.23997725e-06\n","   -4.83667989e-06 -4.28316846e-06]]\n","\n"," ...\n","\n"," [[-3.61159196e-06 -3.65983372e-06 -3.73720215e-06 ...  6.47849278e-06\n","    6.28851844e-06  6.15786213e-06]\n","  [-1.09894678e-05 -1.06376875e-05 -1.00855816e-05 ...  1.65473855e-05\n","    1.58327532e-05  1.51712173e-05]\n","  [-6.00675209e-06 -6.47352405e-06 -7.07771869e-06 ...  1.46841419e-05\n","    1.42988271e-05  1.39686852e-05]\n","  ...\n","  [-1.29968449e-06 -1.40139116e-06 -1.50984711e-06 ...  4.27896759e-06\n","    4.32681844e-06  4.32391499e-06]\n","  [-7.77250878e-06 -8.64579576e-06 -9.75330104e-06 ...  1.63486839e-05\n","    1.67381794e-05  1.70626409e-05]\n","  [-2.30128093e-06 -2.09371946e-06 -1.86187732e-06 ...  1.35729799e-06\n","    1.49089680e-06  1.62723788e-06]]\n","\n"," [[-1.67914270e-06 -1.63420069e-06 -1.57883078e-06 ...  6.17245081e-06\n","    6.24711279e-06  6.30662857e-06]\n","  [ 3.89045539e-06  4.07090824e-06  4.27672350e-06 ... -2.17942251e-07\n","   -6.91890974e-07 -1.02013800e-06]\n","  [-3.55663921e-06 -3.20011103e-06 -2.74019802e-06 ...  9.40403969e-06\n","    9.36214391e-06  9.28337186e-06]\n","  ...\n","  [-4.36177170e-06 -4.19539879e-06 -3.93071979e-06 ...  6.94645562e-06\n","    6.16272777e-06  5.55839944e-06]\n","  [ 1.32731407e-06  1.85557849e-06  2.58755714e-06 ... -6.17629397e-06\n","   -5.68393165e-06 -5.27580907e-06]\n","  [-5.52231265e-06 -4.98309642e-06 -4.35027674e-06 ... -6.73706899e-06\n","   -6.94397074e-06 -7.01419387e-06]]\n","\n"," [[-1.59621257e-06 -1.36454597e-06 -1.07766723e-06 ...  6.27296161e-06\n","    5.91155883e-06  5.64261065e-06]\n","  [-5.07032287e-07 -4.37131824e-07 -4.37578313e-07 ...  3.41682101e-06\n","    3.04139401e-06  2.85374032e-06]\n","  [-1.07403259e-06 -5.05509471e-07  1.23144360e-07 ...  5.18228012e-06\n","    5.41876681e-06  5.58030954e-06]\n","  ...\n","  [ 1.03802108e-06  1.16902660e-06  1.34521997e-06 ... -6.38243104e-07\n","   -3.78368109e-07 -1.62314349e-07]\n","  [ 1.15656626e-06  8.52072422e-07  5.73052042e-07 ...  1.49256814e-06\n","    1.43016115e-06  1.32659212e-06]\n","  [-2.60718525e-06 -2.23198515e-06 -1.78757380e-06 ...  1.08475712e-06\n","    8.99451389e-07  8.26946150e-07]]]\n","(330, 66, 600)\n","(330,)\n"]}]},{"cell_type":"code","source":[" X_train, X_test, y_train, y_test = train_test_split(result_combined, labels, test_size=0.2, random_state=42)"],"metadata":{"id":"oIqKkG42-UO4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","\n","class EEGNet(nn.Module):\n","    def __init__(self, nb_classes=2, kernel_size=60, number_channel=66, signal_length=600,\n","                 dropoutRate=0.5, pooling_size1=4, pooling_size2=4, f1=8, D=2, f2=16,\n","                 norm_rate=0.25):\n","        super(EEGNet, self).__init__()\n","\n","        # First convolution layer\n","        self.conv1 = nn.Conv2d(1, f1, (1, kernel_size), padding=(0, kernel_size // 2), bias=False)\n","        self.batch_norm1 = nn.BatchNorm2d(f1)\n","\n","        # Depthwise convolution\n","        self.depthwise_conv = nn.Conv2d(f1, f1 * D, (number_channel, 1), groups=f1, bias=False)\n","        self.batch_norm2 = nn.BatchNorm2d(f1 * D)\n","        self.elu = nn.ELU()\n","\n","        # Pooling layer\n","        self.avg_pool1 = nn.AvgPool2d((1, pooling_size1))\n","        self.dropout1 = nn.Dropout(dropoutRate)\n","\n","        # Separable convolution\n","        self.separable_conv = nn.Conv2d(f1 * D, f2, (1, 16), padding='same', groups=f1 * D, bias=False)\n","        self.separable_conv_1x1 = nn.Conv2d(f2, f2, (1, 1), padding='same', bias=False)\n","        self.batch_norm3 = nn.BatchNorm2d(f2)\n","\n","        # Second pooling layer\n","        self.avg_pool2 = nn.AvgPool2d((1, pooling_size2))\n","        self.dropout2 = nn.Dropout(dropoutRate)\n","\n","        # Calculate the final flattened size after convolutions and pooling\n","        final_feature_size = 592  # This is the correct flattened size after all layers\n","\n","        # Correct the input size of the classifier to match final_feature_size\n","        self.classifier = nn.Linear(final_feature_size, nb_classes)\n","        self.norm_rate = norm_rate\n","\n","        # Hooks to apply max norm constraints\n","        self.depthwise_conv.register_forward_pre_hook(self.apply_max_norm_depthwise)\n","        self.classifier.register_forward_pre_hook(self.apply_max_norm_classifier)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.batch_norm1(x)\n","        x = self.depthwise_conv(x)\n","        x = self.batch_norm2(x)\n","        x = self.elu(x)\n","        x = self.avg_pool1(x)\n","        x = self.dropout1(x)\n","\n","        x = self.separable_conv(x)\n","        x = self.separable_conv_1x1(x)\n","        x = self.batch_norm3(x)\n","        x = self.elu(x)\n","        x = self.avg_pool2(x)\n","        x = self.dropout2(x)\n","\n","        # Flatten the tensor before passing to the classifier\n","        x = x.view(x.size(0), -1)  # Flatten the feature maps into a single vector\n","\n","        x = self.classifier(x)  # Now the input size to classifier is correct\n","        return x\n","\n","    def apply_max_norm_depthwise(self, module, input):\n","        with torch.no_grad():\n","            norm = self.depthwise_conv.weight.data.norm(2, dim=1, keepdim=True)\n","            desired = torch.clamp(norm, max=1.0)\n","            scale = desired / (norm + 1e-8)\n","            self.depthwise_conv.weight.data *= scale\n","\n","    def apply_max_norm_classifier(self, module, input):\n","        with torch.no_grad():\n","            norm = self.classifier.weight.data.norm(2, dim=0, keepdim=True)\n","            desired = torch.clamp(norm, max=self.norm_rate)\n","            scale = desired / (norm + 1e-8)\n","            self.classifier.weight.data *= scale\n","\n","# Instantiate the model\n","model = EEGNet(nb_classes=2, signal_length=600, number_channel=66)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n"],"metadata":{"id":"8eipcOZ1sV7s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAoe0ViKCKMQ","executionInfo":{"status":"ok","timestamp":1733774848335,"user_tz":-330,"elapsed":6,"user":{"displayName":"Imran Ahmad","userId":"17190214500553653263"}},"outputId":"296bcbfb-69cc-4ced-e30c-a54670bd71bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["EEGNet(\n","  (conv1): Conv2d(1, 8, kernel_size=(1, 60), stride=(1, 1), padding=(0, 30), bias=False)\n","  (batch_norm1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (depthwise_conv): Conv2d(8, 16, kernel_size=(66, 1), stride=(1, 1), groups=8, bias=False)\n","  (batch_norm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (elu): ELU(alpha=1.0)\n","  (avg_pool1): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n","  (dropout1): Dropout(p=0.5, inplace=False)\n","  (separable_conv): Conv2d(16, 16, kernel_size=(1, 16), stride=(1, 1), padding=same, groups=16, bias=False)\n","  (separable_conv_1x1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n","  (batch_norm3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (avg_pool2): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n","  (dropout2): Dropout(p=0.5, inplace=False)\n","  (classifier): Linear(in_features=592, out_features=2, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["# Convert data to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)  # Add channel dimension\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","\n","# Create DataLoader\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"],"metadata":{"id":"tJb7DCajskW8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","epochs = 50\n","train_losses, test_losses = [], []\n","\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for X_batch, y_batch in train_loader:\n","        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(X_batch)\n","        loss = criterion(outputs, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","    train_losses.append(running_loss / len(train_loader))\n","\n","    # Testing loop\n","    model.eval()\n","    test_loss = 0.0\n","    all_preds, all_labels = [], []\n","    with torch.no_grad():\n","        for X_batch, y_batch in test_loader:\n","            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n","            outputs = model(X_batch)\n","            loss = criterion(outputs, y_batch)\n","            test_loss += loss.item()\n","\n","            preds = torch.argmax(outputs, dim=1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(y_batch.cpu().numpy())\n","\n","    test_losses.append(test_loss / len(test_loader))\n","    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]}, Test Loss: {test_losses[-1]}')\n","\n","# Plot training and testing loss\n","plt.plot(train_losses, label='Train Loss')\n","plt.plot(test_losses, label='Test Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"41tE6g0cTjcs"},"execution_count":null,"outputs":[]}]}