{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0lN93dRyfqVKqpdMkmgtH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imranzr/EEG_Based_Auditory_Brain_Computer_Interface_Using_Deep_Learning_and_Machine_Learning_Model/blob/main/Auditory_BCI_Sliding_and_Overlapping_Window_epoching_based_Machine_Learning(ML)_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHaZvftN1hNg",
        "outputId": "efc586b6-b581-49b0-c294-bf14173d2063"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mne"
      ],
      "metadata": {
        "id": "jv3nnSXIMu0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f723c77-9288-4031-f3db-b59711347306"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from mne) (3.8.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from mne) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from mne) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.8.30)\n",
            "Downloading mne-1.8.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyriemann"
      ],
      "metadata": {
        "id": "PGxeXDFPMxnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e4d4576-767e-4b1a-f1eb-3f0aa97bf759"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyriemann\n",
            "  Downloading pyriemann-0.7-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: numpy!=1.24.0 in /usr/local/lib/python3.10/dist-packages (from pyriemann) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyriemann) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.10/dist-packages (from pyriemann) (1.5.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pyriemann) (1.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pyriemann) (3.8.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->pyriemann) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyriemann) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyriemann) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyriemann) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyriemann) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyriemann) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyriemann) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyriemann) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyriemann) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->pyriemann) (1.16.0)\n",
            "Downloading pyriemann-0.7-py2.py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyriemann\n",
            "Successfully installed pyriemann-0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import sys\n",
        "import mne\n",
        "import math\n",
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from pyriemann.estimation import XdawnCovariances\n",
        "from pyriemann.tangentspace import TangentSpace\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, matthews_corrcoef\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "def is_notebook():\n",
        "    try:\n",
        "        shell = get_ipython().__class__.__name__\n",
        "        if shell == 'ZMQInteractiveShell':\n",
        "            return True\n",
        "        elif shell == 'TerminalInteractiveShell':\n",
        "            return False\n",
        "        else:\n",
        "            return False\n",
        "    except NameError:\n",
        "        return False\n",
        "\n",
        "if is_notebook():\n",
        "    args = argparse.Namespace(s=None, c=None)\n",
        "else:\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-s', default=None)\n",
        "    parser.add_argument('-c', default=None, type=int)\n",
        "\n",
        "    args = parser.parse_args(args=[])\n",
        "\n",
        "print(args.s)\n",
        "print(args.c)\n",
        "print(__doc__)\n",
        "\n",
        "subject = 'sub-B'\n",
        "if args.s is not None:\n",
        "    subject = args.s\n",
        "test_class =1\n",
        "if args.c is not None:\n",
        "    test_class = args.c\n",
        "\n",
        "import numpy as np\n",
        "fnum = np.array([[1,4],\n",
        "                 [2,5],\n",
        "                 [3,6]])\n",
        "\n",
        "trig_id = [2,8,32]\n",
        "tasks = ['low', 'low', 'mid', 'mid', 'high', 'high']\n",
        "reject={'eeg':100e-6,'eog':500e-6}\n",
        "\n",
        "import os\n",
        "import json\n",
        "repository_base = os.path.dirname(os.path.dirname(os.path.abspath('/content/drive/MyDrive/dataverse_files/results/sub-B_classification_scores.json')))\n",
        "\n",
        "#repository_base = os.path.dirname(os.path.dirname(os.path.abspath('file_path')))\n",
        "base = os.path.join(repository_base, \"eeg\")\n",
        "save_base = os.path.join(repository_base, \"results\")\n",
        "if not os.path.exists(save_base):\n",
        "    os.makedirs(save_base)\n",
        "\n",
        "Fs = 1000\n",
        "fc = [1, 40]\n",
        "resample = None\n",
        "\n",
        "from scipy.signal import butter, filtfilt\n",
        "def apply_filter(data, b, a):\n",
        "    r = filtfilt(b=b, a=a, x=data)\n",
        "    return r\n",
        "b,a = butter(N = 2, Wn = np.array(fc)/(Fs/2), btype = 'bandpass', output = 'ba')\n",
        "\n",
        "t_file = []\n",
        "nt_file = []\n",
        "target_file = []\n",
        "non_target_file = []\n",
        "\n",
        "for i in range(len(fnum.ravel())):\n",
        "    fname = os.path.join(base, subject, \"eeg\", \"%s_task-%s_run-%d_eeg.vhdr\" % (subject, tasks[i], fnum.ravel()[i]))\n",
        "    print(fname)\n",
        "    if np.any(fnum[test_class-1] == fnum.ravel()[i]):\n",
        "        if isinstance(target_file, list):\n",
        "            target_file = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n",
        "            target_file = target_file.apply_function(apply_filter, channel_wise=True, b=b, a=a)\n",
        "            t_file.append(fnum.ravel()[i])\n",
        "        else:\n",
        "            tmp = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n",
        "            tmp = tmp.apply_function(apply_filter, channel_wise=True, b=b, a=a)\n",
        "            target_file = mne.concatenate_raws([target_file, tmp])\n",
        "            t_file.append(fnum.ravel()[i])\n",
        "    else:\n",
        "        if isinstance(non_target_file, list):\n",
        "            non_target_file = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n",
        "            non_target_file = non_target_file.apply_function(apply_filter, channel_wise=True, b=b, a=a)\n",
        "            nt_file.append(fnum.ravel()[i])\n",
        "        else:\n",
        "            tmp = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n",
        "            tmp = tmp.apply_function(apply_filter, channel_wise=True, b=b, a=a)\n",
        "            non_target_file = mne.concatenate_raws([non_target_file, tmp])\n",
        "            nt_file.append(fnum.ravel()[i])\n",
        "if resample is not None:\n",
        "    target_file.resample(resample)\n",
        "    non_target_file.resample(resample)\n",
        "\n",
        "if resample != None:\n",
        "    target_file.resample(resample)\n",
        "    non_target_file.resample(resample)\n",
        "\n",
        "event_id={'target_stimulus_id':-100,'non_target_stimulus_id':-500}\n",
        "target_eve = mne.events_from_annotations(target_file)\n",
        "target_eve = mne.merge_events(target_eve[0],[trig_id[test_class-1]],event_id['target_stimulus_id'],replace_events=True)\n",
        "\n",
        "non_target_eve = mne.events_from_annotations(non_target_file)\n",
        "non_target_eve = mne.merge_events(non_target_eve[0],[trig_id[test_class-1]],event_id['non_target_stimulus_id'],replace_events=True)\n",
        "\n",
        "tmin,tmax= -0.02, 1.4\n",
        "baseline=(0.0,0.01)\n",
        "target_epochs = mne.Epochs(target_file,events=target_eve, event_id=event_id['target_stimulus_id'], tmin=tmin,tmax=tmax, baseline=baseline, reject=reject,preload = True)"
      ],
      "metadata": {
        "id": "4d9TobesM0OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf73b45-98e0-473c-b1be-b72f5fb87750"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n",
            "Automatically created module for IPython interactive environment\n",
            "/content/drive/MyDrive/dataverse_files/eeg/sub-B/eeg/sub-B_task-low_run-1_eeg.vhdr\n",
            "Extracting parameters from /content/drive/MyDrive/dataverse_files/eeg/sub-B/eeg/sub-B_task-low_run-1_eeg.vhdr...\n",
            "Setting channel info structure...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-fdbca35346cd>:91: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
            "  target_file = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n",
            "<ipython-input-5-fdbca35346cd>:91: RuntimeWarning: Channels contain different lowpass filters. Highest (weakest) filter setting (100.00 Hz) will be stored.\n",
            "  target_file = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading 0 ... 317919  =      0.000 ...   317.919 secs...\n",
            "/content/drive/MyDrive/dataverse_files/eeg/sub-B/eeg/sub-B_task-low_run-4_eeg.vhdr\n",
            "Extracting parameters from /content/drive/MyDrive/dataverse_files/eeg/sub-B/eeg/sub-B_task-low_run-4_eeg.vhdr...\n",
            "Setting channel info structure...\n",
            "Reading 0 ... 312879  =      0.000 ...   312.879 secs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-fdbca35346cd>:95: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
            "  tmp = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n",
            "<ipython-input-5-fdbca35346cd>:95: RuntimeWarning: Channels contain different lowpass filters. Highest (weakest) filter setting (100.00 Hz) will be stored.\n",
            "  tmp = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dataverse_files/eeg/sub-B/eeg/sub-B_task-mid_run-2_eeg.vhdr\n",
            "Extracting parameters from /content/drive/MyDrive/dataverse_files/eeg/sub-B/eeg/sub-B_task-mid_run-2_eeg.vhdr...\n",
            "Setting channel info structure...\n",
            "Reading 0 ... 314879  =      0.000 ...   314.879 secs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-fdbca35346cd>:101: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
            "  non_target_file = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n",
            "<ipython-input-5-fdbca35346cd>:101: RuntimeWarning: Channels contain different lowpass filters. Highest (weakest) filter setting (100.00 Hz) will be stored.\n",
            "  non_target_file = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dataverse_files/eeg/sub-B/eeg/sub-B_task-mid_run-5_eeg.vhdr\n",
            "Extracting parameters from /content/drive/MyDrive/dataverse_files/eeg/sub-B/eeg/sub-B_task-mid_run-5_eeg.vhdr...\n",
            "Setting channel info structure...\n",
            "Reading 0 ... 315879  =      0.000 ...   315.879 secs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-fdbca35346cd>:105: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
            "  tmp = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n",
            "<ipython-input-5-fdbca35346cd>:105: RuntimeWarning: Channels contain different lowpass filters. Highest (weakest) filter setting (100.00 Hz) will be stored.\n",
            "  tmp = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dataverse_files/eeg/sub-B/eeg/sub-B_task-high_run-3_eeg.vhdr\n",
            "Extracting parameters from /content/drive/MyDrive/dataverse_files/eeg/sub-B/eeg/sub-B_task-high_run-3_eeg.vhdr...\n",
            "Setting channel info structure...\n",
            "Reading 0 ... 319199  =      0.000 ...   319.199 secs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-fdbca35346cd>:105: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
            "  tmp = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n",
            "<ipython-input-5-fdbca35346cd>:105: RuntimeWarning: Channels contain different lowpass filters. Highest (weakest) filter setting (100.00 Hz) will be stored.\n",
            "  tmp = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dataverse_files/eeg/sub-B/eeg/sub-B_task-high_run-6_eeg.vhdr\n",
            "Extracting parameters from /content/drive/MyDrive/dataverse_files/eeg/sub-B/eeg/sub-B_task-high_run-6_eeg.vhdr...\n",
            "Setting channel info structure...\n",
            "Reading 0 ... 321519  =      0.000 ...   321.519 secs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-fdbca35346cd>:105: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
            "  tmp = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n",
            "<ipython-input-5-fdbca35346cd>:105: RuntimeWarning: Channels contain different lowpass filters. Highest (weakest) filter setting (100.00 Hz) will be stored.\n",
            "  tmp = mne.io.read_raw_brainvision(fname, preload=True, eog=('hEOG', 'vEOG'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  4', 'Stimulus/S  8', 'Stimulus/S 16', 'Stimulus/S 32', 'Stimulus/S129', 'Stimulus/S132', 'Stimulus/S144']\n",
            "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  1', 'Stimulus/S  2', 'Stimulus/S  4', 'Stimulus/S  8', 'Stimulus/S 16', 'Stimulus/S 32', 'Stimulus/S129', 'Stimulus/S132', 'Stimulus/S144']\n",
            "Not setting metadata\n",
            "119 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 119 events and 1421 original time points ...\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AFz', 'AF4', 'AF8', 'F6']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F5', 'F3', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F6']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "62 bad epochs dropped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sliding and Overlapping Window Epoching"
      ],
      "metadata": {
        "id": "IIbFrsLmY0um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "def find_max_peak_window(data, Fs, window_size_ms=500, overlap_size_ms=100, epoch_index=0):\n",
        "    \"\"\"\n",
        "    Function to find the window with the maximum peak value within a specific epoch and return its start and end indices.\n",
        "    \"\"\"\n",
        "    window_size_samples = int(window_size_ms * Fs / 1000)\n",
        "    overlap_size_samples = int(overlap_size_ms * Fs / 1000)\n",
        "    epoch_data = data[epoch_index]\n",
        "    n_channels, n_times = epoch_data.shape\n",
        "    max_peak_value = -np.inf\n",
        "    max_peak_start_index = None\n",
        "    max_peak_end_index = None\n",
        "    start = 0\n",
        "    while start + window_size_samples <= n_times:\n",
        "        window_data = epoch_data[:, start:start + window_size_samples]\n",
        "        current_peak_value = np.max(window_data)\n",
        "        if current_peak_value > max_peak_value:\n",
        "            max_peak_value = current_peak_value\n",
        "            max_peak_start_index = start\n",
        "            max_peak_end_index = start + window_size_samples - 1\n",
        "        start += (window_size_samples - overlap_size_samples)\n",
        "    print(f\"Epoch {epoch_index + 1} - Max Peak Value: {max_peak_value}\")\n",
        "    print(f\"Epoch {epoch_index + 1} - Window Start Index: {max_peak_start_index}, End Index: {max_peak_end_index}\")\n",
        "    return max_peak_start_index, max_peak_end_index\n",
        "\n",
        "def analyze_all_epochs_max_peaks(data, Fs, window_size_ms=500, overlap_size_ms=100):\n",
        "    \"\"\"\n",
        "    Function to find and print the maximum peak values and corresponding window indices across all epochs.\n",
        "    \"\"\"\n",
        "    n_epochs = data.shape[0]\n",
        "    peak_window_indices = []\n",
        "    for epoch_index in range(n_epochs):\n",
        "        print(f\"\\nAnalyzing Epoch {epoch_index + 1}\")\n",
        "        start_index, end_index = find_max_peak_window(data, Fs, window_size_ms, overlap_size_ms, epoch_index)\n",
        "        peak_window_indices.append((start_index, end_index))\n",
        "    return peak_window_indices\n",
        "\n",
        "def re_epoch_data(data, peak_window_indices):\n",
        "    \"\"\"\n",
        "    Function to re-epoch the data based on the peak window indices.\n",
        "    \"\"\"\n",
        "    re_epoched_data = []\n",
        "    for epoch_index, (start, end) in enumerate(peak_window_indices):\n",
        "        re_epoched_epoch_data = data[epoch_index][:, start:end + 1]\n",
        "        re_epoched_data.append(re_epoched_epoch_data)\n",
        "    re_epoched_data = np.array(re_epoched_data)\n",
        "    print(\"\\nRe-epoching complete.\")\n",
        "    print(\"Re-epoched data shape:\", re_epoched_data.shape)\n",
        "    return re_epoched_data\n",
        "\n",
        "Fs = 1000\n",
        "data = target_epochs.get_data()\n",
        "peak_window_indices = analyze_all_epochs_max_peaks(data, Fs, window_size_ms=500, overlap_size_ms=100)\n",
        "re_epoched_data = re_epoch_data(data, peak_window_indices)\n",
        "\n",
        "from mne import EpochsArray\n",
        "from mne import create_info\n",
        "n_channels = re_epoched_data.shape[1]\n",
        "info = create_info(ch_names=[f'chan{i}' for i in range(n_channels)], sfreq=Fs, ch_types='eeg')\n",
        "re_epoched_epochs = EpochsArray(re_epoched_data, info)\n",
        "print(\"Re-epoched data converted to MNE Epochs:\", re_epoched_epochs)\n",
        "\n",
        "\n",
        "\n",
        "from mne import EpochsArray, create_info\n",
        "n_channels = re_epoched_data.shape[1]\n",
        "info = create_info(ch_names=[f'chan{i}' for i in range(n_channels)], sfreq=Fs, ch_types='eeg')\n",
        "re_epoched_epochs = EpochsArray(re_epoched_data, info)\n",
        "baseline=(0.0,0.01)\n",
        "re_epoched_epochs.apply_baseline(baseline)\n",
        "re_epoched_epochs.filter(l_freq=0.50, h_freq=100.00)\n",
        "print(\"Re-epoched data converted to MNE Epochs and processed with baseline correction and filtering.\")\n",
        "\n",
        "tmin,tmax= -0.0, 0.499\n",
        "baseline=(0.0,0.01)\n",
        "non_target_epochs = mne.Epochs(non_target_file, events=non_target_eve, event_id=event_id['non_target_stimulus_id'], tmin=tmin,tmax=tmax, baseline=baseline, reject=reject,preload = True)\n",
        "\n",
        "\n",
        "import mne\n",
        "tmin, tmax = -0.0, 0.499\n",
        "baseline=(0.0,0.01)\n",
        "non_target_epochs = mne.Epochs(\n",
        "    non_target_file,\n",
        "    events=non_target_eve,\n",
        "    event_id=event_id['non_target_stimulus_id'],\n",
        "    tmin=tmin,\n",
        "    tmax=tmax,\n",
        "    baseline=baseline,\n",
        "    reject=reject,\n",
        "    preload=True\n",
        ")\n",
        "\n",
        "new_channel_names = [f'chan{i}' for i in range(len(non_target_epochs.ch_names))]\n",
        "rename_dict = dict(zip(non_target_epochs.ch_names, new_channel_names))\n",
        "non_target_epochs.rename_channels(rename_dict)\n",
        "print(\"Updated channel names:\", non_target_epochs.ch_names)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ca9n5f42REh5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e7fd349-4759-4e2a-b4ee-67db9202b9fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analyzing Epoch 1\n",
            "Epoch 1 - Max Peak Value: 5.3609090909090905e-05\n",
            "Epoch 1 - Window Start Index: 800, End Index: 1299\n",
            "\n",
            "Analyzing Epoch 2\n",
            "Epoch 2 - Max Peak Value: 2.9702295397418008e-05\n",
            "Epoch 2 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 3\n",
            "Epoch 3 - Max Peak Value: 1.9700354081974367e-05\n",
            "Epoch 3 - Window Start Index: 800, End Index: 1299\n",
            "\n",
            "Analyzing Epoch 4\n",
            "Epoch 4 - Max Peak Value: 1.8520261664344037e-05\n",
            "Epoch 4 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 5\n",
            "Epoch 5 - Max Peak Value: 2.7344734807680046e-05\n",
            "Epoch 5 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 6\n",
            "Epoch 6 - Max Peak Value: 1.838181818181818e-05\n",
            "Epoch 6 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 7\n",
            "Epoch 7 - Max Peak Value: 1.841774308675113e-05\n",
            "Epoch 7 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 8\n",
            "Epoch 8 - Max Peak Value: 1.8918203042186065e-05\n",
            "Epoch 8 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 9\n",
            "Epoch 9 - Max Peak Value: 1.5520013599621606e-05\n",
            "Epoch 9 - Window Start Index: 800, End Index: 1299\n",
            "\n",
            "Analyzing Epoch 10\n",
            "Epoch 10 - Max Peak Value: 2.7196571958875588e-05\n",
            "Epoch 10 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 11\n",
            "Epoch 11 - Max Peak Value: 2.5073326719635557e-05\n",
            "Epoch 11 - Window Start Index: 800, End Index: 1299\n",
            "\n",
            "Analyzing Epoch 12\n",
            "Epoch 12 - Max Peak Value: 1.6327272727272726e-05\n",
            "Epoch 12 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 13\n",
            "Epoch 13 - Max Peak Value: 3.764303997485425e-05\n",
            "Epoch 13 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 14\n",
            "Epoch 14 - Max Peak Value: 1.9012048358191983e-05\n",
            "Epoch 14 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 15\n",
            "Epoch 15 - Max Peak Value: 1.8906455355758987e-05\n",
            "Epoch 15 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 16\n",
            "Epoch 16 - Max Peak Value: 2.1624880412508232e-05\n",
            "Epoch 16 - Window Start Index: 800, End Index: 1299\n",
            "\n",
            "Analyzing Epoch 17\n",
            "Epoch 17 - Max Peak Value: 9.620909090909091e-05\n",
            "Epoch 17 - Window Start Index: 800, End Index: 1299\n",
            "\n",
            "Analyzing Epoch 18\n",
            "Epoch 18 - Max Peak Value: 2.15913926881218e-05\n",
            "Epoch 18 - Window Start Index: 800, End Index: 1299\n",
            "\n",
            "Analyzing Epoch 19\n",
            "Epoch 19 - Max Peak Value: 1.6390909090909092e-05\n",
            "Epoch 19 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 20\n",
            "Epoch 20 - Max Peak Value: 2.3563636363636365e-05\n",
            "Epoch 20 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 21\n",
            "Epoch 21 - Max Peak Value: 1.4130419631901537e-05\n",
            "Epoch 21 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 22\n",
            "Epoch 22 - Max Peak Value: 2.8812978579693052e-05\n",
            "Epoch 22 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 23\n",
            "Epoch 23 - Max Peak Value: 3.6230919779578724e-05\n",
            "Epoch 23 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 24\n",
            "Epoch 24 - Max Peak Value: 1.758243621398397e-05\n",
            "Epoch 24 - Window Start Index: 800, End Index: 1299\n",
            "\n",
            "Analyzing Epoch 25\n",
            "Epoch 25 - Max Peak Value: 3.595864189200104e-05\n",
            "Epoch 25 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 26\n",
            "Epoch 26 - Max Peak Value: 1.6541720058604406e-05\n",
            "Epoch 26 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 27\n",
            "Epoch 27 - Max Peak Value: 2.3057450683904316e-05\n",
            "Epoch 27 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 28\n",
            "Epoch 28 - Max Peak Value: 2.2745454545454542e-05\n",
            "Epoch 28 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 29\n",
            "Epoch 29 - Max Peak Value: 2.810136598968121e-05\n",
            "Epoch 29 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 30\n",
            "Epoch 30 - Max Peak Value: 3.232115773706842e-05\n",
            "Epoch 30 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 31\n",
            "Epoch 31 - Max Peak Value: 1.6052820666576997e-05\n",
            "Epoch 31 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 32\n",
            "Epoch 32 - Max Peak Value: 2.1189628933343627e-05\n",
            "Epoch 32 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 33\n",
            "Epoch 33 - Max Peak Value: 3.144141146424527e-05\n",
            "Epoch 33 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 34\n",
            "Epoch 34 - Max Peak Value: 1.7320428444006832e-05\n",
            "Epoch 34 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 35\n",
            "Epoch 35 - Max Peak Value: 2.503369482683002e-05\n",
            "Epoch 35 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 36\n",
            "Epoch 36 - Max Peak Value: 1.51391943721272e-05\n",
            "Epoch 36 - Window Start Index: 800, End Index: 1299\n",
            "\n",
            "Analyzing Epoch 37\n",
            "Epoch 37 - Max Peak Value: 2.1064796532735176e-05\n",
            "Epoch 37 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 38\n",
            "Epoch 38 - Max Peak Value: 2.9833554332995465e-05\n",
            "Epoch 38 - Window Start Index: 800, End Index: 1299\n",
            "\n",
            "Analyzing Epoch 39\n",
            "Epoch 39 - Max Peak Value: 2.9337361500995426e-05\n",
            "Epoch 39 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 40\n",
            "Epoch 40 - Max Peak Value: 1.973258985239427e-05\n",
            "Epoch 40 - Window Start Index: 800, End Index: 1299\n",
            "\n",
            "Analyzing Epoch 41\n",
            "Epoch 41 - Max Peak Value: 3.1377428115286455e-05\n",
            "Epoch 41 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 42\n",
            "Epoch 42 - Max Peak Value: 3.3317563016357825e-05\n",
            "Epoch 42 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 43\n",
            "Epoch 43 - Max Peak Value: 8.85e-05\n",
            "Epoch 43 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 44\n",
            "Epoch 44 - Max Peak Value: 0.00027293636363636363\n",
            "Epoch 44 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 45\n",
            "Epoch 45 - Max Peak Value: 4.531532262520558e-05\n",
            "Epoch 45 - Window Start Index: 800, End Index: 1299\n",
            "\n",
            "Analyzing Epoch 46\n",
            "Epoch 46 - Max Peak Value: 5.298272031598832e-05\n",
            "Epoch 46 - Window Start Index: 800, End Index: 1299\n",
            "\n",
            "Analyzing Epoch 47\n",
            "Epoch 47 - Max Peak Value: 4.478853886911688e-05\n",
            "Epoch 47 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 48\n",
            "Epoch 48 - Max Peak Value: 3.1732357359426895e-05\n",
            "Epoch 48 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 49\n",
            "Epoch 49 - Max Peak Value: 2.1054816789322042e-05\n",
            "Epoch 49 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Analyzing Epoch 50\n",
            "Epoch 50 - Max Peak Value: 2.4528132515297194e-05\n",
            "Epoch 50 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 51\n",
            "Epoch 51 - Max Peak Value: 3.4859355669108964e-05\n",
            "Epoch 51 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 52\n",
            "Epoch 52 - Max Peak Value: 6.660909090909091e-05\n",
            "Epoch 52 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 53\n",
            "Epoch 53 - Max Peak Value: 0.00014803636363636363\n",
            "Epoch 53 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 54\n",
            "Epoch 54 - Max Peak Value: 3.399550724883309e-05\n",
            "Epoch 54 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 55\n",
            "Epoch 55 - Max Peak Value: 3.352727272727273e-05\n",
            "Epoch 55 - Window Start Index: 400, End Index: 899\n",
            "\n",
            "Analyzing Epoch 56\n",
            "Epoch 56 - Max Peak Value: 1.9809090909090907e-05\n",
            "Epoch 56 - Window Start Index: 800, End Index: 1299\n",
            "\n",
            "Analyzing Epoch 57\n",
            "Epoch 57 - Max Peak Value: 4.047290811657939e-05\n",
            "Epoch 57 - Window Start Index: 0, End Index: 499\n",
            "\n",
            "Re-epoching complete.\n",
            "Re-epoched data shape: (57, 66, 500)\n",
            "Not setting metadata\n",
            "57 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Re-epoched data converted to MNE Epochs: <EpochsArray | 57 events (all good), 0 – 0.499 s (baseline off), ~14.4 MB, data loaded,\n",
            " '1': 57>\n",
            "Not setting metadata\n",
            "57 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Applying baseline correction (mode: mean)\n",
            "Setting up band-pass filter from 0.5 - 1e+02 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 100.00 Hz\n",
            "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
            "- Filter length: 6601 samples (6.601 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-2346cbd8a145>:71: RuntimeWarning: filter_length (6601) is longer than the signal (500), distortion is likely. Reduce filter length or filter a longer signal.\n",
            "  re_epoched_epochs.filter(l_freq=0.50, h_freq=100.00)\n",
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=1)]: Done 2177 tasks      | elapsed:    1.2s\n",
            "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=1)]: Done 3041 tasks      | elapsed:    1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Re-epoched data converted to MNE Epochs and processed with baseline correction and filtering.\n",
            "Not setting metadata\n",
            "237 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 237 events and 500 original time points ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 3527 tasks      | elapsed:    2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['FT9']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F4', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp2']\n",
            "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8', 'F6']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AFz', 'AF4', 'AF8', 'F6']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "48 bad epochs dropped\n",
            "Not setting metadata\n",
            "237 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 237 events and 500 original time points ...\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['FT9']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F4', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp2']\n",
            "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8', 'F6']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp2', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AFz', 'AF4', 'AF8', 'F6']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8']\n",
            "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2', 'AF7', 'AF4', 'AF8']\n",
            "48 bad epochs dropped\n",
            "Updated channel names: ['chan0', 'chan1', 'chan2', 'chan3', 'chan4', 'chan5', 'chan6', 'chan7', 'chan8', 'chan9', 'chan10', 'chan11', 'chan12', 'chan13', 'chan14', 'chan15', 'chan16', 'chan17', 'chan18', 'chan19', 'chan20', 'chan21', 'chan22', 'chan23', 'chan24', 'chan25', 'chan26', 'chan27', 'chan28', 'chan29', 'chan30', 'chan31', 'chan32', 'chan33', 'chan34', 'chan35', 'chan36', 'chan37', 'chan38', 'chan39', 'chan40', 'chan41', 'chan42', 'chan43', 'chan44', 'chan45', 'chan46', 'chan47', 'chan48', 'chan49', 'chan50', 'chan51', 'chan52', 'chan53', 'chan54', 'chan55', 'chan56', 'chan57', 'chan58', 'chan59', 'chan60', 'chan61', 'chan62', 'chan63', 'chan64', 'chan65']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = mne.concatenate_epochs([re_epoched_epochs, non_target_epochs])\n",
        "epochs = epochs.copy().pick_types(eeg=True, eog=False)"
      ],
      "metadata": {
        "id": "VdwmEZ0wYzKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa18c407-49f5-4644-b23d-87cb9a588709"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "246 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-e84d836bf4c9>:1: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
            "  epochs = mne.concatenate_epochs([re_epoched_epochs, non_target_epochs])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "nF7AR3l1WwDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clf = make_pipeline(XdawnCovariances(8),\n",
        "                    TangentSpace(metric='logeuclid'),\n",
        "                    LogisticRegression( penalty='l1', solver='liblinear', multi_class='ovr'))\n",
        "\n",
        "epochs_data = epochs.get_data()\n",
        "labels = epochs.events[:, -1]\n",
        "preds = np.zeros(len(labels))\n",
        "\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "preds = np.empty(len(labels))\n",
        "for train_idx, test_idx in cv.split(epochs_data, labels):\n",
        "    clf.fit(epochs_data[train_idx], labels[train_idx])\n",
        "    preds[test_idx] = clf.predict(epochs_data[test_idx])\n",
        "\n",
        "report = classification_report(labels, preds, target_names=['non-target', 'target'], output_dict=True)\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "XbmzPgFcQ7yk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e3c9d20-a2b5-45cb-b930-5eb27d9ede50"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'non-target': {'precision': 0.983957219251337, 'recall': 0.9735449735449735, 'f1-score': 0.9787234042553191, 'support': 189.0}, 'target': {'precision': 0.9152542372881356, 'recall': 0.9473684210526315, 'f1-score': 0.9310344827586207, 'support': 57.0}, 'accuracy': 0.967479674796748, 'macro avg': {'precision': 0.9496057282697363, 'recall': 0.9604566972988025, 'f1-score': 0.9548789435069699, 'support': 246.0}, 'weighted avg': {'precision': 0.9680382356257171, 'recall': 0.967479674796748, 'f1-score': 0.967673532201206, 'support': 246.0}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Support Vector Machine (SVM)"
      ],
      "metadata": {
        "id": "j2Z_8QXoW2YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "clf = make_pipeline(XdawnCovariances(8),\n",
        "                    TangentSpace(metric='logeuclid'),\n",
        "                    SVC(kernel='linear', C=1, decision_function_shape='ovr'))\n",
        "\n",
        "\n",
        "epochs_data = epochs.get_data()\n",
        "labels = epochs.events[:, -1]\n",
        "preds = np.zeros(len(labels))\n",
        "\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "preds = np.empty(len(labels))\n",
        "for train_idx, test_idx in cv.split(epochs_data, labels):\n",
        "    clf.fit(epochs_data[train_idx], labels[train_idx])\n",
        "    train_preds = clf.predict(epochs_data[train_idx])\n",
        "    test_preds = clf.predict(epochs_data[test_idx])\n",
        "    train_accuracy = accuracy_score(labels[train_idx], train_preds)\n",
        "    test_accuracy = accuracy_score(labels[test_idx], test_preds)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    train_loss = np.mean(train_preds != labels[train_idx])\n",
        "    test_loss = np.mean(test_preds != labels[test_idx])\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    preds[test_idx] = test_preds\n",
        "report = classification_report(labels, preds, target_names=['non-target', 'target'], output_dict=True)\n",
        "print(report)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_0qB57AwW0hR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c65333b1-0cab-4de0-c9cb-bb3466cd4b64"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'non-target': {'precision': 0.958974358974359, 'recall': 0.9894179894179894, 'f1-score': 0.9739583333333334, 'support': 189.0}, 'target': {'precision': 0.9607843137254902, 'recall': 0.8596491228070176, 'f1-score': 0.9074074074074074, 'support': 57.0}, 'accuracy': 0.959349593495935, 'macro avg': {'precision': 0.9598793363499246, 'recall': 0.9245335561125034, 'f1-score': 0.9406828703703705, 'support': 246.0}, 'weighted avg': {'precision': 0.9593937387337673, 'recall': 0.959349593495935, 'f1-score': 0.9585379968383018, 'support': 246.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "ADEK5YAuW-WG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = make_pipeline(XdawnCovariances(8),\n",
        "                    TangentSpace(metric='logeuclid'),\n",
        "                    RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "\n",
        "epochs_data = epochs.get_data()\n",
        "labels = epochs.events[:, -1]\n",
        "preds = np.zeros(len(labels))\n",
        "\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "preds = np.empty(len(labels))\n",
        "for train_idx, test_idx in cv.split(epochs_data, labels):\n",
        "\n",
        "    clf.fit(epochs_data[train_idx], labels[train_idx])\n",
        "    train_preds = clf.predict(epochs_data[train_idx])\n",
        "    test_preds = clf.predict(epochs_data[test_idx])\n",
        "    train_accuracy = accuracy_score(labels[train_idx], train_preds)\n",
        "    test_accuracy = accuracy_score(labels[test_idx], test_preds)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    train_loss = np.mean(train_preds != labels[train_idx])\n",
        "    test_loss = np.mean(test_preds != labels[test_idx])\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    preds[test_idx] = test_preds\n",
        "\n",
        "report = classification_report(labels, preds, target_names=['non-target', 'target'], output_dict=True)\n",
        "print(report)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CXNqmDXQW-AI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2955e81c-f18f-41b8-e05f-e4d696c10be8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'non-target': {'precision': 0.875, 'recall': 1.0, 'f1-score': 0.9333333333333333, 'support': 189.0}, 'target': {'precision': 1.0, 'recall': 0.5263157894736842, 'f1-score': 0.6896551724137931, 'support': 57.0}, 'accuracy': 0.8902439024390244, 'macro avg': {'precision': 0.9375, 'recall': 0.763157894736842, 'f1-score': 0.8114942528735632, 'support': 246.0}, 'weighted avg': {'precision': 0.9039634146341463, 'recall': 0.8902439024390244, 'f1-score': 0.8768713204373423, 'support': 246.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Polynomial Logistic Regression"
      ],
      "metadata": {
        "id": "tMVovSgXXDcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = make_pipeline(XdawnCovariances(8),\n",
        "                    TangentSpace(metric='logeuclid'),\n",
        "                    PolynomialFeatures(degree=2, include_bias=False),\n",
        "                    LogisticRegression(penalty='l2', solver='liblinear', multi_class='ovr'))\n",
        "\n",
        "epochs_data = epochs.get_data()\n",
        "labels = epochs.events[:, -1]\n",
        "preds = np.zeros(len(labels))\n",
        "\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "preds = np.empty(len(labels))\n",
        "for train_idx, test_idx in cv.split(epochs_data, labels):\n",
        "    clf.fit(epochs_data[train_idx], labels[train_idx])\n",
        "    train_preds = clf.predict(epochs_data[train_idx])\n",
        "    test_preds = clf.predict(epochs_data[test_idx])\n",
        "    train_accuracy = accuracy_score(labels[train_idx], train_preds)\n",
        "    test_accuracy = accuracy_score(labels[test_idx], test_preds)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    train_loss = np.mean(train_preds != labels[train_idx])\n",
        "    test_loss = np.mean(test_preds != labels[test_idx])\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    preds[test_idx] = test_preds\n",
        "\n",
        "\n",
        "report = classification_report(labels, preds, target_names=['non-target', 'target'], output_dict=True)\n",
        "print(report)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3pwbacSQXEuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM_Plt\n",
        "\n",
        "epochs_range = range(1, len(train_accuracies) + 1)\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "ax1.plot(epochs_range, train_accuracies, label='Train Accuracy', marker='o')\n",
        "ax1.plot(epochs_range, test_accuracies, label='Test Accuracy', marker='x')\n",
        "ax1.set_title('Train and Test Accuracy')\n",
        "ax1.set_xlabel('Fold')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "\n",
        "\n",
        "for i in range(len(train_accuracies)):\n",
        "    ax1.annotate(f'{train_accuracies[i]:.2f}', (epochs_range[i], train_accuracies[i]),\n",
        "                 textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=8)\n",
        "    ax1.annotate(f'{test_accuracies[i]:.2f}', (epochs_range[i], test_accuracies[i]),\n",
        "                 textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=8)\n",
        "\n",
        "ax2.plot(epochs_range, train_losses, label='Train Loss', marker='o')\n",
        "ax2.plot(epochs_range, test_losses, label='Test Loss', marker='x')\n",
        "ax2.set_title('Train and Test Loss')\n",
        "ax2.set_xlabel('Fold')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.legend()\n",
        "\n",
        "for i in range(len(train_losses)):\n",
        "    ax2.annotate(f'{train_losses[i]:.2f}', (epochs_range[i], train_losses[i]),\n",
        "                 textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=8)\n",
        "    ax2.annotate(f'{test_losses[i]:.2f}', (epochs_range[i], test_losses[i]),\n",
        "                 textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "cm = confusion_matrix(labels, preds)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['non-target', 'target'], yticklabels=['non-target', 'target'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Random_forest_plt\n",
        "\n",
        "epochs_range = range(1, len(train_accuracies) + 1)\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "ax1.plot(epochs_range, train_accuracies, label='Train Accuracy', marker='o')\n",
        "ax1.plot(epochs_range, test_accuracies, label='Test Accuracy', marker='x')\n",
        "ax1.set_title('Train and Test Accuracy')\n",
        "ax1.set_xlabel('Fold')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "\n",
        "\n",
        "for i in range(len(train_accuracies)):\n",
        "    ax1.annotate(f'{train_accuracies[i]:.2f}', (epochs_range[i], train_accuracies[i]),\n",
        "                 textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=8)\n",
        "    ax1.annotate(f'{test_accuracies[i]:.2f}', (epochs_range[i], test_accuracies[i]),\n",
        "                 textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=8)\n",
        "\n",
        "ax2.plot(epochs_range, train_losses, label='Train Loss', marker='o')\n",
        "ax2.plot(epochs_range, test_losses, label='Test Loss', marker='x')\n",
        "ax2.set_title('Train and Test Loss')\n",
        "ax2.set_xlabel('Fold')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.legend()\n",
        "\n",
        "for i in range(len(train_losses)):\n",
        "    ax2.annotate(f'{train_losses[i]:.2f}', (epochs_range[i], train_losses[i]),\n",
        "                 textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=8)\n",
        "    ax2.annotate(f'{test_losses[i]:.2f}', (epochs_range[i], test_losses[i]),\n",
        "                 textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "cm = confusion_matrix(labels, preds)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['non-target', 'target'], yticklabels=['non-target', 'target'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# plt_poly_l_Reg\n",
        "epochs_range = range(1, len(train_accuracies) + 1)\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "ax1.plot(epochs_range, train_accuracies, label='Train Accuracy', marker='o')\n",
        "ax1.plot(epochs_range, test_accuracies, label='Test Accuracy', marker='x')\n",
        "ax1.set_title('Train and Test Accuracy')\n",
        "ax1.set_xlabel('Fold')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "\n",
        "for i in range(len(train_accuracies)):\n",
        "    ax1.annotate(f'{train_accuracies[i]:.2f}', (epochs_range[i], train_accuracies[i]),\n",
        "                 textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=8)\n",
        "    ax1.annotate(f'{test_accuracies[i]:.2f}', (epochs_range[i], test_accuracies[i]),\n",
        "                 textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=8)\n",
        "ax2.plot(epochs_range, train_losses, label='Train Loss', marker='o')\n",
        "ax2.plot(epochs_range, test_losses, label='Test Loss', marker='x')\n",
        "ax2.set_title('Train and Test Loss')\n",
        "ax2.set_xlabel('Fold')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.legend()\n",
        "\n",
        "\n",
        "for i in range(len(train_losses)):\n",
        "    ax2.annotate(f'{train_losses[i]:.2f}', (epochs_range[i], train_losses[i]),\n",
        "                 textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=8)\n",
        "    ax2.annotate(f'{test_losses[i]:.2f}', (epochs_range[i], test_losses[i]),\n",
        "                 textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "cm = confusion_matrix(labels, preds)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['non-target', 'target'], yticklabels=['non-target', 'target'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "La1t9vql2bCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UtgblDRa2rEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2KZO-Mo3AfH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
